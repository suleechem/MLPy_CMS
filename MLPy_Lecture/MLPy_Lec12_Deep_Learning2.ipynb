{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31fee594-c399-4707-8a76-c2e8a411dd5b",
   "metadata": {},
   "source": [
    "# XOR Deep Learning Architecture\n",
    "- 딥러닝에서는1개 이상의 은닉층(hidden layer)를 만들수 있음.\n",
    "- 각 은닉층은 임의 개수의 노드(node)로 구성 됨.\n",
    "- 은닉층과 노드 개수가 많아질 수록 학습 속도는 느려지므로 적적한 개수 결정.\n",
    "  \n",
    "<img src = \"http://cmseng.skku.edu/CMSLecture/ML/img/12-1.png\" style=\"max-width: 80%; height: auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6243e4-62f7-46e5-bd1f-721788454ebc",
   "metadata": {},
   "source": [
    "<img src = \"http://cmseng.skku.edu/CMSLecture/ML/img/12-2.png\" style=\"max-width: 80%; height: auto;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa6eab8a-367a-4caa-9cc3-0739a98819ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 수치미분 함수\n",
    "\n",
    "def numerical_derivative(f, x):\n",
    "    delta_x = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index        \n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x) # f(x+delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val - delta_x \n",
    "        fx2 = f(x) # f(x-delta_x)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val \n",
    "        it.iternext()   \n",
    "        \n",
    "    return grad\n",
    "\n",
    "# sigmoid 함수\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00fffc81-01c8-4c92-9bd5-bad2b9a402e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogicGate:\n",
    "        \n",
    "    def __init__(self, gate_name, xdata, tdata):\n",
    "        \n",
    "        self.name = gate_name\n",
    "        \n",
    "        # 입력 데이터, 정답 데이터 초기화\n",
    "        self.__xdata = xdata.reshape(4,2)  # 4개의 입력데이터 x1, x2 에 대하여 batch 처리 행렬\n",
    "        self.__tdata = tdata.reshape(4,1)  # 4개의 입력데이터 x1, x2 에 대한 각각의 계산 값 행렬\n",
    "        \n",
    "        # 2층 hidden layer unit : 6개 가정,  가중치 W2, 바이어스 b2 초기화\n",
    "        self.__W2 = np.random.rand(2,6)  # weight, 2 X 6 matrix\n",
    "        self.__b2 = np.random.rand(6)\n",
    "        \n",
    "        # 3층 output layer unit : 1 개 , 가중치 W3, 바이어스 b3 초기화\n",
    "        self.__W3 = np.random.rand(6,1)\n",
    "        self.__b3 = np.random.rand(1)\n",
    "                        \n",
    "        # 학습률 learning rate 초기화\n",
    "        self.__learning_rate = 1e-2\n",
    "    \n",
    "        print(self.name + \" object is created\")\n",
    "            \n",
    "    def feed_forward(self):        # feed forward 를 통하여 손실함수(cross-entropy) 값 계산\n",
    "        \n",
    "        delta = 1e-7    # log 무한대 발산 방지\n",
    "    \n",
    "        z2 = np.dot(self.__xdata, self.__W2) + self.__b2  # 은닉층의 선형회귀 값\n",
    "        a2 = sigmoid(z2)                                  # 은닉층의 출력\n",
    "        \n",
    "        z3 = np.dot(a2, self.__W3) + self.__b3            # 출력층의 선형회귀 값\n",
    "        y = a3 = sigmoid(z3)                              # 출력층의 출력\n",
    "    \n",
    "        # cross-entropy \n",
    "        return  -np.sum( self.__tdata*np.log(y + delta) + (1-self.__tdata)*np.log((1 - y)+delta ) )    \n",
    "    \n",
    "    def loss_val(self):          # 외부 출력을 위한 손실함수(cross-entropy) 값 계산 \n",
    "        \n",
    "        delta = 1e-7    # log 무한대 발산 방지\n",
    "    \n",
    "        z2 = np.dot(self.__xdata, self.__W2) + self.__b2  # 은닉층의 선형회귀 값\n",
    "        a2 = sigmoid(z2)                                  # 은닉층의 출력\n",
    "        \n",
    "        z3 = np.dot(a2, self.__W3) + self.__b3            # 출력층의 선형회귀 값\n",
    "        y = a3 = sigmoid(z3)                              # 출력층의 출력\n",
    "    \n",
    "        # cross-entropy \n",
    "        return  -np.sum( self.__tdata*np.log(y + delta) + (1-self.__tdata)*np.log((1 - y)+delta ) )\n",
    "    \n",
    "    \n",
    "    # 수치미분을 이용하여 손실함수가 최소가 될때 까지 학습하는 함수\n",
    "    def train(self):\n",
    "        \n",
    "        f = lambda x : self.feed_forward()\n",
    "        \n",
    "        print(\"Initial loss value = \", self.loss_val())\n",
    "        \n",
    "        for step in  range(20001):\n",
    "            \n",
    "            self.__W2 -= self.__learning_rate * numerical_derivative(f, self.__W2)\n",
    "    \n",
    "            self.__b2 -= self.__learning_rate * numerical_derivative(f, self.__b2)\n",
    "        \n",
    "            self.__W3 -= self.__learning_rate * numerical_derivative(f, self.__W3)\n",
    "    \n",
    "            self.__b3 -= self.__learning_rate * numerical_derivative(f, self.__b3)\n",
    "    \n",
    "            if (step % 400 == 0):\n",
    "                print(\"step = \", step, \"  , loss value = \", self.loss_val())\n",
    "                \n",
    "    \n",
    "    # query, 즉 미래 값 예측 함수\n",
    "    def predict(self, xdata):\n",
    "        \n",
    "        z2 = np.dot(xdata, self.__W2) + self.__b2         # 은닉층의 선형회귀 값\n",
    "        a2 = sigmoid(z2)                                  # 은닉층의 출력\n",
    "        \n",
    "        z3 = np.dot(a2, self.__W3) + self.__b3            # 출력층의 선형회귀 값\n",
    "        y = a3 = sigmoid(z3)                              # 출력층의 출력\n",
    "    \n",
    "        if y > 0.5:\n",
    "            result = 1  # True\n",
    "        else:\n",
    "            result = 0  # False\n",
    "    \n",
    "        return y, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "382b4d9d-6505-44e6-971f-e7700e63eb69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AND object is created\n",
      "Initial loss value =  10.258336800584477\n",
      "step =  0   , loss value =  9.923878092077246\n",
      "step =  400   , loss value =  2.257250218409506\n",
      "step =  800   , loss value =  2.1337927888786097\n",
      "step =  1200   , loss value =  1.9566527423987157\n",
      "step =  1600   , loss value =  1.7009839122402464\n",
      "step =  2000   , loss value =  1.377771439646323\n",
      "step =  2400   , loss value =  1.0462641248463829\n",
      "step =  2800   , loss value =  0.774294988209459\n",
      "step =  3200   , loss value =  0.5764658836039058\n",
      "step =  3600   , loss value =  0.4378571940818907\n",
      "step =  4000   , loss value =  0.34109531087643025\n",
      "step =  4400   , loss value =  0.27264838671894104\n",
      "step =  4800   , loss value =  0.22317794660308693\n",
      "step =  5200   , loss value =  0.1865444382971421\n",
      "step =  5600   , loss value =  0.15875854232673117\n",
      "step =  6000   , loss value =  0.13720831772675102\n",
      "step =  6400   , loss value =  0.1201545022091695\n",
      "step =  6800   , loss value =  0.10641474596637843\n",
      "step =  7200   , loss value =  0.0951677497907854\n",
      "step =  7600   , loss value =  0.08583086369824777\n",
      "step =  8000   , loss value =  0.07798243367540066\n",
      "step =  8400   , loss value =  0.07131162659929116\n",
      "step =  8800   , loss value =  0.06558537612197114\n",
      "step =  9200   , loss value =  0.06062618405945733\n",
      "step =  9600   , loss value =  0.05629693280227914\n",
      "step =  10000   , loss value =  0.05249030997081625\n",
      "step =  10400   , loss value =  0.04912132197019793\n",
      "step =  10800   , loss value =  0.04612191181436624\n",
      "step =  11200   , loss value =  0.04343703375268301\n",
      "step =  11600   , loss value =  0.041021751857410846\n",
      "step =  12000   , loss value =  0.038839068635689616\n",
      "step =  12400   , loss value =  0.03685828107509656\n",
      "step =  12800   , loss value =  0.03505372252471834\n",
      "step =  13200   , loss value =  0.03340379013320553\n",
      "step =  13600   , loss value =  0.03189018594401494\n",
      "step =  14000   , loss value =  0.030497319492539168\n",
      "step =  14400   , loss value =  0.029211833656612632\n",
      "step =  14800   , loss value =  0.028022225420348656\n",
      "step =  15200   , loss value =  0.026918540348618618\n",
      "step =  15600   , loss value =  0.02589212476365991\n",
      "step =  16000   , loss value =  0.024935423432504315\n",
      "step =  16400   , loss value =  0.0240418134049845\n",
      "step =  16800   , loss value =  0.023205466760251876\n",
      "step =  17200   , loss value =  0.0224212366175079\n",
      "step =  17600   , loss value =  0.02168456198143976\n",
      "step =  18000   , loss value =  0.02099138792340969\n",
      "step =  18400   , loss value =  0.020338098317136736\n",
      "step =  18800   , loss value =  0.01972145890505049\n",
      "step =  19200   , loss value =  0.0191385689071017\n",
      "step =  19600   , loss value =  0.01858681972642689\n",
      "step =  20000   , loss value =  0.018063859577099578\n"
     ]
    }
   ],
   "source": [
    "# AND Gate 객체 생성 및 training\n",
    "\n",
    "xdata = np.array([ [0, 0], [0, 1], [1, 0], [1, 1] ])\n",
    "tdata = np.array([0, 0, 0, 1])\n",
    "\n",
    "and_obj = LogicGate(\"AND\", xdata, tdata)\n",
    "\n",
    "and_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a1d2bd2-63de-45ca-9a76-8ea0ca69b152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([9.26200639e-05]), 0)\n",
      "(array([0.00478046]), 0)\n",
      "(array([0.00477648]), 0)\n",
      "(array([0.99164333]), 1)\n"
     ]
    }
   ],
   "source": [
    "# AND Gate prediction\n",
    "\n",
    "test_data = np.array([ [0, 0], [0, 1], [1, 0], [1, 1] ])\n",
    "\n",
    "for data in test_data:\n",
    "    print(and_obj.predict(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8589e551-0197-43d3-a27b-596c77323e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OR object is created\n",
      "Initial loss value =  2.304122541200034\n",
      "step =  0   , loss value =  2.2943325332477102\n",
      "step =  400   , loss value =  1.927260470667521\n",
      "step =  800   , loss value =  1.698011249815765\n",
      "step =  1200   , loss value =  1.3746417586682826\n",
      "step =  1600   , loss value =  1.0194128037972796\n",
      "step =  2000   , loss value =  0.7222983075890542\n",
      "step =  2400   , loss value =  0.513358478227762\n",
      "step =  2800   , loss value =  0.37581939148087573\n",
      "step =  3200   , loss value =  0.285427179900028\n",
      "step =  3600   , loss value =  0.22442497076711265\n",
      "step =  4000   , loss value =  0.18179989698651453\n",
      "step =  4400   , loss value =  0.1509701755954736\n",
      "step =  4800   , loss value =  0.127964231935384\n",
      "step =  5200   , loss value =  0.11032130585866651\n",
      "step =  5600   , loss value =  0.09646832033091562\n",
      "step =  6000   , loss value =  0.08536782904235315\n",
      "step =  6400   , loss value =  0.07631537232395062\n",
      "step =  6800   , loss value =  0.0688197030337826\n",
      "step =  7200   , loss value =  0.06252994613581771\n",
      "step =  7600   , loss value =  0.057190041857971385\n",
      "step =  8000   , loss value =  0.05260948782002335\n",
      "step =  8400   , loss value =  0.04864408101621914\n",
      "step =  8800   , loss value =  0.04518295191025641\n",
      "step =  9200   , loss value =  0.04213965208544427\n",
      "step =  9600   , loss value =  0.039445910938047654\n",
      "step =  10000   , loss value =  0.037047185545289615\n",
      "step =  10400   , loss value =  0.03489943783417628\n",
      "step =  10800   , loss value =  0.03296676624585054\n",
      "step =  11200   , loss value =  0.031219641798480757\n",
      "step =  11600   , loss value =  0.029633577930986796\n",
      "step =  12000   , loss value =  0.028188115904198577\n",
      "step =  12400   , loss value =  0.026866042647614347\n",
      "step =  12800   , loss value =  0.025652781831970978\n",
      "step =  13200   , loss value =  0.024535915439860487\n",
      "step =  13600   , loss value =  0.02350480464291586\n",
      "step =  14000   , loss value =  0.02255028696536359\n",
      "step =  14400   , loss value =  0.0216644325699168\n",
      "step =  14800   , loss value =  0.020840346744410897\n",
      "step =  15200   , loss value =  0.020072008773801386\n",
      "step =  15600   , loss value =  0.01935413967782055\n",
      "step =  16000   , loss value =  0.018682093007124305\n",
      "step =  16400   , loss value =  0.018051764179502567\n",
      "step =  16800   , loss value =  0.01745951481498148\n",
      "step =  17200   , loss value =  0.016902109276109203\n",
      "step =  17600   , loss value =  0.016376661194888106\n",
      "step =  18000   , loss value =  0.015880588214182773\n",
      "step =  18400   , loss value =  0.015411573519561027\n",
      "step =  18800   , loss value =  0.014967533011050235\n",
      "step =  19200   , loss value =  0.014546587180508757\n",
      "step =  19600   , loss value =  0.01414703693191128\n",
      "step =  20000   , loss value =  0.013767342719152208\n"
     ]
    }
   ],
   "source": [
    "# OR Gate 객체 생성 및 training\n",
    "\n",
    "xdata = np.array([ [0, 0], [0, 1], [1, 0], [1, 1] ])\n",
    "tdata = np.array([0, 1, 1, 1])\n",
    "\n",
    "or_obj = LogicGate(\"OR\", xdata, tdata)\n",
    "\n",
    "or_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79011626-f0a6-46a2-95b0-c3a29dcf45a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.00819173]), 0)\n",
      "(array([0.99736488]), 1)\n",
      "(array([0.99718786]), 1)\n",
      "(array([0.99991242]), 1)\n"
     ]
    }
   ],
   "source": [
    "# OR Gate prediction\n",
    "\n",
    "test_data = np.array([ [0, 0], [0, 1], [1, 0], [1, 1] ])\n",
    "\n",
    "for data in test_data:\n",
    "    print(or_obj.predict(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c90ed674-59cc-4df8-af7d-46b59c5ce9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAND object is created\n",
      "Initial loss value =  3.094325917146323\n",
      "step =  0   , loss value =  3.0643750666653577\n",
      "step =  400   , loss value =  2.246483150950328\n",
      "step =  800   , loss value =  2.146319105209918\n",
      "step =  1200   , loss value =  1.9912507731842344\n",
      "step =  1600   , loss value =  1.7156755299912771\n",
      "step =  2000   , loss value =  1.3572148251680713\n",
      "step =  2400   , loss value =  1.0336821869153145\n",
      "step =  2800   , loss value =  0.7700607120130298\n",
      "step =  3200   , loss value =  0.5723252085314177\n",
      "step =  3600   , loss value =  0.43221809122067767\n",
      "step =  4000   , loss value =  0.3346964067607979\n",
      "step =  4400   , loss value =  0.2662316851458586\n",
      "step =  4800   , loss value =  0.2171360684196023\n",
      "step =  5200   , loss value =  0.18102642950102796\n",
      "step =  5600   , loss value =  0.1537881516604565\n",
      "step =  6000   , loss value =  0.13275410979803193\n",
      "step =  6400   , loss value =  0.11616506441216695\n",
      "step =  6800   , loss value =  0.10283493222245454\n",
      "step =  7200   , loss value =  0.09194555858855027\n",
      "step =  7600   , loss value =  0.08291990625756929\n",
      "step =  8000   , loss value =  0.07534241353622309\n",
      "step =  8400   , loss value =  0.06890798302688628\n",
      "step =  8800   , loss value =  0.06338862801589887\n",
      "step =  9200   , loss value =  0.05861121610514236\n",
      "step =  9600   , loss value =  0.054442325627723345\n",
      "step =  10000   , loss value =  0.05077775065889849\n",
      "step =  10400   , loss value =  0.04753510167747491\n",
      "step =  10800   , loss value =  0.04464850475832266\n",
      "step =  11200   , loss value =  0.042064747392076815\n",
      "step =  11600   , loss value =  0.03974043731764278\n",
      "step =  12000   , loss value =  0.037639881206453715\n",
      "step =  12400   , loss value =  0.03573348192823492\n",
      "step =  12800   , loss value =  0.033996514207517564\n",
      "step =  13200   , loss value =  0.03240817969228886\n",
      "step =  13600   , loss value =  0.030950870660469226\n",
      "step =  14000   , loss value =  0.0296095911500137\n",
      "step =  14400   , loss value =  0.0283714980365191\n",
      "step =  14800   , loss value =  0.027225534344878677\n",
      "step =  15200   , loss value =  0.02616213409772547\n",
      "step =  15600   , loss value =  0.025172983098831602\n",
      "step =  16000   , loss value =  0.024250823786945964\n",
      "step =  16400   , loss value =  0.023389295062706233\n",
      "step =  16800   , loss value =  0.022582800058344062\n",
      "step =  17200   , loss value =  0.021826396376862428\n",
      "step =  17600   , loss value =  0.02111570450962342\n",
      "step =  18000   , loss value =  0.020446831045845423\n",
      "step =  18400   , loss value =  0.019816303984246733\n",
      "step =  18800   , loss value =  0.019221017997928816\n",
      "step =  19200   , loss value =  0.018658187925650604\n",
      "step =  19600   , loss value =  0.018125309094339216\n",
      "step =  20000   , loss value =  0.017620123339825423\n"
     ]
    }
   ],
   "source": [
    "# NAND Gate 객체 생성 및 training\n",
    "\n",
    "xdata = np.array([ [0, 0], [0, 1], [1, 0], [1, 1] ])\n",
    "tdata = np.array([1, 1, 1, 0])\n",
    "\n",
    "nand_obj = LogicGate(\"NAND\", xdata, tdata)\n",
    "\n",
    "nand_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5691a999-ee65-4b86-a19a-822c896a2d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.9999235]), 1)\n",
      "(array([0.99550804]), 1)\n",
      "(array([0.99531982]), 1)\n",
      "(array([0.00831601]), 0)\n"
     ]
    }
   ],
   "source": [
    "# NAND Gate prediction\n",
    "\n",
    "test_data = np.array([ [0, 0], [0, 1], [1, 0], [1, 1] ])\n",
    "\n",
    "for data in test_data:\n",
    "    print(nand_obj.predict(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4df7eda-4910-492f-bd29-6c413c788a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XOR object is created\n",
      "Initial loss value =  6.4991371632638115\n",
      "step =  0   , loss value =  6.34191789054433\n",
      "step =  400   , loss value =  2.7729140058982003\n",
      "step =  800   , loss value =  2.767421034645885\n",
      "step =  1200   , loss value =  2.7617679884132307\n",
      "step =  1600   , loss value =  2.7554652813699625\n",
      "step =  2000   , loss value =  2.747965675978508\n",
      "step =  2400   , loss value =  2.7386047402867226\n",
      "step =  2800   , loss value =  2.726544097578281\n",
      "step =  3200   , loss value =  2.7107212861088557\n",
      "step =  3600   , loss value =  2.689814677389422\n",
      "step =  4000   , loss value =  2.662235845868076\n",
      "step =  4400   , loss value =  2.626176201916909\n",
      "step =  4800   , loss value =  2.5797741050925613\n",
      "step =  5200   , loss value =  2.521491852715468\n",
      "step =  5600   , loss value =  2.4506404377611437\n",
      "step =  6000   , loss value =  2.3675982934637982\n",
      "step =  6400   , loss value =  2.273136356391934\n",
      "step =  6800   , loss value =  2.1669602577338694\n",
      "step =  7200   , loss value =  2.0465008458027025\n",
      "step =  7600   , loss value =  1.9072679579609206\n",
      "step =  8000   , loss value =  1.7456827276718383\n",
      "step =  8400   , loss value =  1.5635013860237719\n",
      "step =  8800   , loss value =  1.3701690437852267\n",
      "step =  9200   , loss value =  1.1799927140021276\n",
      "step =  9600   , loss value =  1.0059700209443565\n",
      "step =  10000   , loss value =  0.8554317164045132\n",
      "step =  10400   , loss value =  0.7298745697736753\n",
      "step =  10800   , loss value =  0.627159969918591\n",
      "step =  11200   , loss value =  0.5437148442541113\n",
      "step =  11600   , loss value =  0.4758569110529228\n",
      "step =  12000   , loss value =  0.4203628216544706\n",
      "step =  12400   , loss value =  0.37461185119668805\n",
      "step =  12800   , loss value =  0.3365464563409367\n",
      "step =  13200   , loss value =  0.3045754608459553\n",
      "step =  13600   , loss value =  0.2774735343977787\n",
      "step =  14000   , loss value =  0.25429528709936616\n",
      "step =  14400   , loss value =  0.23430741383606546\n",
      "step =  14800   , loss value =  0.21693700340573152\n",
      "step =  15200   , loss value =  0.20173279704516928\n",
      "step =  15600   , loss value =  0.18833631728815914\n",
      "step =  16000   , loss value =  0.1764603468405132\n",
      "step =  16400   , loss value =  0.16587282655957328\n",
      "step =  16800   , loss value =  0.1563847387851089\n",
      "step =  17200   , loss value =  0.1478409268075151\n",
      "step =  17600   , loss value =  0.14011308687900492\n",
      "step =  18000   , loss value =  0.13309437719357267\n",
      "step =  18400   , loss value =  0.12669523845453956\n",
      "step =  18800   , loss value =  0.12084012882633563\n",
      "step =  19200   , loss value =  0.11546495408513788\n",
      "step =  19600   , loss value =  0.11051503025447787\n",
      "step =  20000   , loss value =  0.10594345709274763\n"
     ]
    }
   ],
   "source": [
    "# XOR Gate 객체 생성\n",
    "\n",
    "xdata = np.array([ [0, 0], [0, 1], [1, 0], [1, 1] ])\n",
    "tdata = np.array([0, 1, 1, 0])\n",
    "\n",
    "\n",
    "xor_obj = LogicGate(\"XOR\", xdata, tdata)\n",
    "\n",
    "xor_obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1cb9efa6-d378-439d-a922-3009419ef63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.00595721]), 0)\n",
      "(array([0.97426299]), 1)\n",
      "(array([0.97055108]), 1)\n",
      "(array([0.04304948]), 0)\n"
     ]
    }
   ],
   "source": [
    "test_data = np.array([ [0, 0], [0, 1], [1, 0], [1, 1] ])\n",
    "\n",
    "for data in test_data:\n",
    "    print(xor_obj.predict(data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
