{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46dc570b",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "<img src = \"http://cmseng.skku.edu/CMSLecture/ML/img/9-1.png\" style=\"max-width: 80%; height: auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b4dbe4",
   "metadata": {},
   "source": [
    "* training data 특성과 관계 등을 파악 한 후에, <font color=red>미지의 입력 데이터의 결과가 어떤 종류의 값으로 분류 될 수 있는지 예측</font>하는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b572fee4",
   "metadata": {},
   "source": [
    "<img src = \"http://cmseng.skku.edu/CMSLecture/ML/img/9-2.png\" style=\"max-width: 80%; height: auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a82f4d",
   "metadata": {},
   "source": [
    "### Rogistic Regression 알고리즘 \n",
    "1. Traning data 특성과 분포를 나타내는 최적의 직선을 찾고 <font color=blue>Linear regression</font>\n",
    "2. 그 직선을 기준으로 데이트를 분류해주는 <font color=blue>Classification</font> 알고리즘.\n",
    "\n",
    "<img src = \"http://cmseng.skku.edu/CMSLecture/ML/img/9-3.png\" style=\"max-width: 80%; height: auto;\">\n",
    "<img src = \"http://cmseng.skku.edu/CMSLecture/ML/img/9-4.png\"style=\"max-width: 80%; height: auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593aa4b9",
   "metadata": {},
   "source": [
    "### Sigmoid 함수\n",
    "* 출력값 $y$가 $1$ 또는 $0$만 가져야 하는 분류$(classification)$ 시스템에서, 함수값으로 $0\\sim1$ 사이의 값을 가지는 $sigmoid$ 함수를 사용 할 수 있음.\n",
    "* $linear \\ regression$의 결과 값$(z=Wx+b)$이 어떤 값을 가지더라도, $sigmoid$ 함수값$(y=sigmoid(z))$은 $0\\sim1$ 사이값을 가가지며, <font color=red>$sigmoid(z) < 0.5$ 이면 결과값 $y=0$ , $sigmoid(z) \\ge 0.5$ 이면 결과값 $y=1$</font>로 정의하여 $classification$ 시스템을 구현\n",
    "<font size=3>\n",
    "* $ \\displaystyle\n",
    "z = Wx+b \\rightarrow sigmoid(z) = \\sigma(z) =\\frac{1}{1+e^{-z}}$\n",
    "* $ \\displaystyle y=\\frac{1}{1+e^{-(Wx+b)}}\n",
    "$</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89221fcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (6, 3)\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['lines.linewidth'] = 2\n",
    "\n",
    "x = np.linspace(-8, 8, 1000)\n",
    "y = 1/(1+np.exp(-x))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y)\n",
    "\n",
    "plt.title('sigmoid')\n",
    "plt.grid(color='0.8')\n",
    "ax.spines['left'].set_position(('data',0)) \n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False) \n",
    "ax.spines['bottom'].set_position(('data',0)) \n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9808512c",
   "metadata": {},
   "source": [
    "### 손실함수 $(cross-entropy)$\n",
    "\n",
    "* $classfication$ 최종 출력 값 $y$는 $sigmoid$함수에 의해 논리적으로 $0 \\ or \\ 1$ 이기때문에, 연속값을 갖는 $linear \\ regression$때와는 다른 손실함수가 필요함.\n",
    "\n",
    "- $ \\displaystyle y=\\frac{1}{1+e^{-(Wx+b)}}\\ , \\ \\ \\ t_i= 0 \\ or \\ 1$\n",
    "\n",
    "- <font color=red>\n",
    " $ \\displaystyle cross-entropy: \\ E(W,b)= - \\sum_{i=1}^{n}{\\{t_i \\log{y_i}+(1-t_i)\\log{(1-y_i)}\\}} $\n",
    "</font>\n",
    "\n",
    "- <font color=blue> 손실함수 $E(W,b)$를 최소화하는 $W \\ and \\ b$   </font>\n",
    "\n",
    "<font color=blue><b>\n",
    "- $ \\displaystyle W = W - \\alpha \\frac{\\partial{E(W,b)}}{\\partial{W}} \\ \\ \\ \\ , \\ \\ \\ \\ \n",
    "     b = b - \\alpha \\frac{\\partial{E(W,b)}}{\\partial{b}}$\n",
    "</b></font>\n",
    "\n",
    "\n",
    "- $\\alpha$는 학습율$(learning \\ rate)$</font>, $W$값이 감소 또는 증가하는 비율을 나타냄."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c83c3d",
   "metadata": {},
   "source": [
    "### 손실함수$(loss \\ function) \\ cross-entropy$ 유도\n",
    "* $classfication$ 최종 <font color=red>출력 값 $y$는 $0 \\ or \\ 1$ </font>이 되어야 함.\n",
    "* $sigmoid$함수의 출력값은 $0 \\sim 1$의 값으로 <b>확률적</b>의미를 갖기 때문에 <b>확률변수 $C$</b>를 이용해 출력 값을 나타낼 수 있음.\n",
    "* 즉, 출력값이 $0 \\ or \\ 1$ 이 될 확률이 최대가 되도록 가중치 W와 바이어스 b를 결정함.\n",
    "* $0 \\ or \\ 1$의 분류가 아닌 <b>다른 정답 t 가 있다면, 정답 t가 될 확률</b>이 최대가 되도록 가중치 W와 바이어스 b를 결정함.\n",
    "\n",
    "<img src = \"http://cmseng.skku.edu/CMSLecture/ML/img/9-5.png\" style=\"max-width: 80%; height: auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c0d566",
   "metadata": {},
   "source": [
    "## Logistic regression using python\n",
    "<img src = \"http://cmseng.skku.edu/CMSLecture/ML/img/9-6.png\" style=\"max-width: 80%; height: auto;\">\n",
    "<img src = \"http://cmseng.skku.edu/CMSLecture/ML/img/9-7.png\" style=\"max-width: 80%; height: auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8b5258",
   "metadata": {},
   "source": [
    "### 1. Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29084e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 2)\n",
      "(10, 1)\n",
      "(10, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.array([[2,0],[4,0],[6,0],[8,0],[10,0],[12,0],[14,1],[16,1],[18,1],[20,1]])\n",
    "x_data = data[:,[0]]\n",
    "t_data = data[:,[-1]]\n",
    "\n",
    "print(data.shape)\n",
    "print(x_data.shape)\n",
    "print(t_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe9cff7",
   "metadata": {},
   "source": [
    "## 2. 임의의 직선 $y=Wx+b$ 정의 (임의의 $W, \\ b$ 초기화)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4814e04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W = [[0.1680784]], W.shape = (1, 1), b = [0.525293], b.shape = (1,)\n"
     ]
    }
   ],
   "source": [
    "W = np.random.rand(1,1)\n",
    "b = np.random.rand(1)\n",
    "\n",
    "print(f\"W = {W}, W.shape = {W.shape}, b = {b}, b.shape = {b.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e697c7f",
   "metadata": {},
   "source": [
    "## 3. 손실함수 $E(W)$ 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dee491e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    y = 1 / (1+np.exp(-x))\n",
    "    return y\n",
    "\n",
    "def loss_func(x,t):\n",
    "    delta = 1e-7\n",
    "    \n",
    "    z = np.dot(x,W) + b\n",
    "    y = sigmoid(z)\n",
    "    \n",
    "    return -np.sum(t*np.log(y+delta)+(1-t)*np.log((1-y)+delta))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b76789",
   "metadata": {},
   "source": [
    "## 4. 수치미분 numerical_derivative 및 utility 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab53ce76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_derivative(f,x):  \n",
    "    delta_x = 1e-4\n",
    "    grad = np.zeros_like(x)  \n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    while not it.finished:\n",
    "        idx=it.multi_index\n",
    "        tmp_val=x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x) \n",
    "        \n",
    "        x[idx] = float(tmp_val) - delta_x\n",
    "        fx2 = f(x)  \n",
    "        grad[idx] = (fx1 - fx2)/(2*delta_x)\n",
    "\n",
    "        x[idx] = tmp_val\n",
    "        it.iternext()\n",
    "        \n",
    "    return grad\n",
    "\n",
    "def error_val(x,t):\n",
    "    delta = 1e-7\n",
    "    z=np.dot(x,W)+b\n",
    "    y=sigmoid(z)\n",
    "    return -np.sum(t*np.log(y+delta)+(1-t)*np.log((1-y)+delta))\n",
    "\n",
    "def predict(x):\n",
    "    z=np.dot(x,W)+b\n",
    "    y=sigmoid(z)\n",
    "    \n",
    "    if y > 0.5:\n",
    "        result = 1\n",
    "    else:\n",
    "        result = 0\n",
    "    \n",
    "    return y, result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdd8316",
   "metadata": {},
   "source": [
    "## 5. 학습율(learning rate) 초기화 및 $W, b$ 업데이트\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec70368b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial error value = 11.488941352439015, initial W = [[0.1680784]]\n",
      "step = 0, error_value = 12.731741078010579, W = [[-0.17402504]], b = [0.54115042]\n",
      "step = 400, error_value = 2.757732115595379, W = [[0.28355673]], b = [-4.1552353]\n",
      "step = 800, error_value = 1.775469768624206, W = [[0.45545462]], b = [-5.66895806]\n",
      "step = 1200, error_value = 1.5131728511438, W = [[0.53229587]], b = [-6.69207554]\n",
      "step = 1600, error_value = 1.349227285719083, W = [[0.59327152]], b = [-7.50173966]\n",
      "step = 2000, error_value = 1.2336025224417615, W = [[0.64460445]], b = [-8.18188035]\n",
      "step = 2400, error_value = 1.1459639011904084, W = [[0.68937675]], b = [-8.77404692]\n",
      "step = 2800, error_value = 1.076282503555517, W = [[0.72935682]], b = [-9.3020576]\n",
      "step = 3200, error_value = 1.0189604889356108, W = [[0.76566086]], b = [-9.78093017]\n",
      "step = 3600, error_value = 0.9705910744028702, W = [[0.79904232]], b = [-10.22079065]\n",
      "step = 4000, error_value = 0.9289638773390821, W = [[0.83003585]], b = [-10.62881623]\n",
      "step = 4400, error_value = 0.8925721973433723, W = [[0.85903575]], b = [-11.01029444]\n",
      "step = 4800, error_value = 0.860347880984261, W = [[0.88634192]], b = [-11.36924258]\n",
      "step = 5200, error_value = 0.8315090702854167, W = [[0.91218825]], b = [-11.70879062]\n",
      "step = 5600, error_value = 0.8054680631464898, W = [[0.93676099]], b = [-12.03142879]\n",
      "step = 6000, error_value = 0.7817730844106522, W = [[0.96021109]], b = [-12.3391737]\n",
      "step = 6400, error_value = 0.7600701241030244, W = [[0.98266279]], b = [-12.63368335]\n",
      "step = 6800, error_value = 0.7400771397791315, W = [[1.00421963]], b = [-12.9163389]\n",
      "step = 7200, error_value = 0.721566144470791, W = [[1.02496896]], b = [-13.1883042]\n",
      "step = 7600, error_value = 0.7043504765119823, W = [[1.04498515]], b = [-13.45056998]\n",
      "step = 8000, error_value = 0.6882755647204123, W = [[1.06433215]], b = [-13.70398717]\n",
      "step = 8400, error_value = 0.6732121063075439, W = [[1.08306534]], b = [-13.9492926]\n",
      "step = 8800, error_value = 0.6590509446961723, W = [[1.10123308]], b = [-14.18712892]\n",
      "step = 9200, error_value = 0.6456991671876533, W = [[1.11887783]], b = [-14.41806033]\n",
      "step = 9600, error_value = 0.6330770925595962, W = [[1.13603711]], b = [-14.64258511]\n",
      "step = 10000, error_value = 0.6211159176774363, W = [[1.15274427]], b = [-14.86114575]\n"
     ]
    }
   ],
   "source": [
    "learning_rate=1e-2\n",
    "\n",
    "f = lambda x: loss_func(x_data,t_data)  # f(x) = loass_func(x_data,y_data)\n",
    "\n",
    "print(f\"initial error value = {error_val(x_data,t_data)}, initial W = {W}\")\n",
    "\n",
    "for step in range(10001):\n",
    "    W-= learning_rate*numerical_derivative(f,W)\n",
    "    b-= learning_rate*numerical_derivative(f,b)\n",
    "    \n",
    "    if(step % 400 ==0):\n",
    "        print(f\"step = {step}, error_value = {error_val(x_data,t_data)}, W = {W}, b = {b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bdc85ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.11627958e-05]] 0\n",
      "[[0.99129838]] 1\n"
     ]
    }
   ],
   "source": [
    "(real_val,logical_val)=predict(3)\n",
    "print(real_val, logical_val)\n",
    "\n",
    "(real_val,logical_val)=predict(17)\n",
    "print(real_val, logical_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775f49f8",
   "metadata": {},
   "source": [
    "## 6. Multi-variable Logistic Regression Code\n",
    "\n",
    "<img src = \"http://cmseng.skku.edu/CMSLecture/ML/img/9-8.png\" style=\"max-width: 80%; height: auto;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a894684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W=[[0.39580251]\n",
      " [0.32763732]], W.shape=(2, 1), b=[0.30922069], b.shape=(1,)\n",
      "initial error value = 17.77920829872341, initial W = [[0.39580251]\n",
      " [0.32763732]]\n",
      "step = 0, error_value = 7.821055709889517, W = [[0.19892496]\n",
      " [0.07239022]], b = [0.27680515]\n",
      "step = 400, error_value = 2.2177453441712762, W = [[ 0.42743632]\n",
      " [-0.08253774]], b = [-2.73087511]\n",
      "step = 800, error_value = 1.5693862823541869, W = [[ 0.54136875]\n",
      " [-0.02414727]], b = [-4.32982828]\n",
      "step = 1200, error_value = 1.2681507067345292, W = [[0.62740555]\n",
      " [0.01050733]], b = [-5.42377743]\n",
      "step = 1600, error_value = 1.0906396994638243, W = [[0.69704747]\n",
      " [0.03536861]], b = [-6.26438571]\n",
      "step = 2000, error_value = 0.9713462800742997, W = [[0.75584899]\n",
      " [0.05525296]], b = [-6.95369674]\n",
      "step = 2400, error_value = 0.8842408927313138, W = [[0.80689288]\n",
      " [0.07231805]], b = [-7.54275291]\n",
      "step = 2800, error_value = 0.8169258809710815, W = [[0.85207028]\n",
      " [0.08768617]], b = [-8.06057967]\n",
      "step = 3200, error_value = 0.7627321701575785, W = [[0.89262899]\n",
      " [0.10199888]], b = [-8.52518843]\n",
      "step = 3600, error_value = 0.7177425028063978, W = [[0.9294394 ]\n",
      " [0.11564616]], b = [-8.94849209]\n",
      "step = 4000, error_value = 0.6794973421677646, W = [[0.96313618]\n",
      " [0.12887394]], b = [-9.33876411]\n",
      "step = 4400, error_value = 0.6463695138137977, W = [[0.99419945]\n",
      " [0.14183966]], b = [-9.70197632]\n",
      "step = 4800, error_value = 0.6172362677826462, W = [[1.02300397]\n",
      " [0.15464315]], b = [-10.04257585]\n",
      "step = 5200, error_value = 0.5912957004171131, W = [[1.04985024]\n",
      " [0.1673451 ]], b = [-10.36396063]\n",
      "step = 5600, error_value = 0.5679583362766014, W = [[1.07498476]\n",
      " [0.17997886]], b = [-10.66878328]\n",
      "step = 6000, error_value = 0.5467801662977079, W = [[1.0986136 ]\n",
      " [0.19255846]], b = [-10.95915263]\n",
      "step = 6400, error_value = 0.5274196865922247, W = [[1.12091165]\n",
      " [0.20508443]], b = [-11.23677161]\n",
      "step = 6800, error_value = 0.5096094185130875, W = [[1.14202901]\n",
      " [0.21754816]], b = [-11.50303421]\n",
      "step = 7200, error_value = 0.493136484943416, W = [[1.16209552]\n",
      " [0.22993531]], b = [-11.75909535]\n",
      "step = 7600, error_value = 0.4778290310616489, W = [[1.18122408]\n",
      " [0.24222844]], b = [-12.0059223]\n",
      "step = 8000, error_value = 0.4635465234978048, W = [[1.19951307]\n",
      " [0.25440902]], b = [-12.24433317]\n",
      "step = 8400, error_value = 0.45017268792532594, W = [[1.21704837]\n",
      " [0.26645888]], b = [-12.47502628]\n",
      "step = 8800, error_value = 0.4376102817393538, W = [[1.2339049 ]\n",
      " [0.27836125]], b = [-12.69860276]\n",
      "step = 9200, error_value = 0.42577716840560925, W = [[1.25014803]\n",
      " [0.29010138]], b = [-12.91558426]\n",
      "step = 9600, error_value = 0.414603331260247, W = [[1.26583471]\n",
      " [0.30166686]], b = [-13.12642688]\n",
      "step = 10000, error_value = 0.4040285757286439, W = [[1.28101461]\n",
      " [0.31304776]], b = [-13.33153227]\n",
      "[ 3 17] (2,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.01526701]), 0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_data = np.array([[2,4],[4,11],[6,6],[8,5],[10,7],[12,16],[14,8],[16,3],[18,7]])\n",
    "t_data = np.array([0,0,0,0,1,1,1,1,1]).reshape(9,1)\n",
    "\n",
    "# print(x_data, x_data.shape)\n",
    "# print(y_data, y_data.shape)\n",
    "\n",
    "W = np.random.rand(2,1)\n",
    "b = np.random.rand(1)\n",
    "print(f\"W={W}, W.shape={W.shape}, b={b}, b.shape={b.shape}\")\n",
    "\n",
    "def sigmoid(x):\n",
    "    y = 1/(1+np.exp(-x))\n",
    "    return y\n",
    "                   \n",
    "def loss_func(x,t):\n",
    "    delta = 1e-7\n",
    "    z=np.dot(x,W)+b\n",
    "    y=sigmoid(z)\n",
    "    return -np.sum(t*np.log(y+delta)+(1-t)*np.log((1-y)+delta))\n",
    "\n",
    "def numerical_derivative(f,x):\n",
    "    delta_x = 1e-4\n",
    "    grad = np.zeros_like(x) \n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    while not it.finished:\n",
    "        idx=it.multi_index\n",
    "        tmp_val=x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x) \n",
    "        \n",
    "        x[idx] = float(tmp_val) - delta_x\n",
    "        fx2 = f(x)  \n",
    "        grad[idx] = (fx1 - fx2)/(2*delta_x)\n",
    "\n",
    "        x[idx] = tmp_val\n",
    "        it.iternext()\n",
    "        \n",
    "    return grad\n",
    "\n",
    "def error_val(x,t):\n",
    "    delta = 1e-7\n",
    "    z=np.dot(x,W)+b\n",
    "    y=sigmoid(z)\n",
    "    return -np.sum(t*np.log(y)+(1-t)*np.log(1-y))\n",
    "            \n",
    "def predict(x):\n",
    "    z=np.dot(x,W)+b\n",
    "    y=sigmoid(z)\n",
    "    if y > 0.5:\n",
    "        result = 1\n",
    "    else:\n",
    "        result = 0\n",
    "    return y,result\n",
    "\n",
    "learning_rate=1e-2\n",
    "\n",
    "f = lambda x: loss_func(x_data,t_data)  # f(x) = loass_func(x_data,y_data)\n",
    "\n",
    "print(f\"initial error value = {error_val(x_data,t_data)}, initial W = {W}\")\n",
    "\n",
    "for step in range(10001):\n",
    "    W -= learning_rate*numerical_derivative(f,W)\n",
    "    b -= learning_rate*numerical_derivative(f,b)\n",
    "    \n",
    "    if(step % 400 ==0):\n",
    "        print(f\"step = {step}, error_value = {error_val(x_data,t_data)}, W = {W}, b = {b}\")\n",
    "\n",
    "test_data = np.array([3,17])\n",
    "print(test_data,test_data.shape)\n",
    "predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fcb3176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3 17] [0.01526701] 0\n",
      "[ 7 17] [0.72259732] 1\n",
      "[5 8] [0.01186675] 0\n",
      "[7 2] [0.02324072] 0\n",
      "[10  0] [0.37252817] 0\n",
      "[12  0] [0.88499874] 1\n",
      "[ 0 12] [6.94413114e-05] 0\n",
      "[10 16] [0.98887505] 1\n"
     ]
    }
   ],
   "source": [
    "test_data = np.array([3,17])\n",
    "(real_val,logical_val)=predict(test_data)\n",
    "print(test_data, real_val, logical_val)\n",
    "\n",
    "test_data = np.array([[7,17],[5,8],[7,2],[10,0],[12,0],[0,12],[10,16]])\n",
    "for test in test_data[:,:]:\n",
    "    (real_val,logical_val)=predict(test)\n",
    "    print(test, real_val, logical_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
