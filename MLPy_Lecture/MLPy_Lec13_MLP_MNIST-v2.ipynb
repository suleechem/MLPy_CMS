{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1e8d3f6-8ebe-4473-b72b-7d9239c57db9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# 수치미분 함수\n",
    "\n",
    "def numerical_derivative(f, x):\n",
    "    delta_x = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index        \n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x) # f(x+delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val - delta_x \n",
    "        fx2 = f(x) # f(x-delta_x)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val \n",
    "        it.iternext()   \n",
    "        \n",
    "    return grad\n",
    "\n",
    "# sigmoid 함수\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4e5141d-b783-46fc-b173-c9b75e9d406a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MNIST_Test Class\n",
    "\n",
    "class MNIST_Test:\n",
    "    \n",
    "    # 생성자\n",
    "    # xdata, tdata => numpy.array(...)\n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        \n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "        \n",
    "        # # 은닉층 가중치  W2  Xavier/He 방법으로 self.W2 가중치 초기화\n",
    "        # self.W2 = np.random.randn(self.input_nodes, self.hidden_nodes) / np.sqrt(self.input_nodes/2)\n",
    "        # self.b2 = np.random.rand(self.hidden_nodes)      \n",
    "        \n",
    "        # # 출력층 가중치는 W3  Xavier/He 방법으로 self.W3 가중치 초기화\n",
    "        # self.W3 = np.random.randn(self.hidden_nodes, self.output_nodes) / np.sqrt(self.hidden_nodes/2)\n",
    "        # self.b3 = np.random.rand(self.output_nodes)      \n",
    "        \n",
    "        # 2층 hidden layer unit \n",
    "        # 가중치 W, 바이어스 b 초기화\n",
    "        self.W2 = np.random.rand(input_nodes, hidden_nodes)  # W2 = (784 X 100)\n",
    "        self.b2 = np.random.rand(hidden_nodes)               # b2 = (100,)\n",
    "        \n",
    "        # 3층 output layer unit : 1 개 \n",
    "        self.W3 = np.random.rand(hidden_nodes,output_nodes)   # W3=(100 X 100)\n",
    "        self.b3 = np.random.rand(output_nodes)                # b3 = (10,)\n",
    "                        \n",
    "        # 학습률 learning rate 초기화\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        print(\"MNIST_Test object is created !!!\")\n",
    "       \n",
    "    def feed_forward(self):\n",
    "        \n",
    "        delta = 1e-7    # log 무한대 발산 방지\n",
    "    \n",
    "        z1 = np.dot(self.input_data, self.W2) + self.b2\n",
    "        y1 = sigmoid(z1)\n",
    "        \n",
    "        z2 = np.dot(y1, self.W3) + self.b3\n",
    "        y = sigmoid(z2)\n",
    "    \n",
    "        # cross-entropy \n",
    "        return  -np.sum( self.target_data*np.log(y + delta) + (1-self.target_data)*np.log((1 - y)+delta ) )\n",
    "\n",
    "    # 수치미분을 이용하여 손실함수가 최소가 될때 까지 학습하는 함수\n",
    "    def train(self, input_data, target_data):\n",
    "        \n",
    "        self.input_data = input_data\n",
    "        self.target_data = target_data\n",
    "        \n",
    "        f = lambda x : self.feed_forward()\n",
    "        \n",
    "        self.W2 -= self.learning_rate * numerical_derivative(f, self.W2)\n",
    "    \n",
    "        self.b2 -= self.learning_rate * numerical_derivative(f, self.b2)\n",
    "        \n",
    "        self.W3 -= self.learning_rate * numerical_derivative(f, self.W3)\n",
    "    \n",
    "        self.b3 -= self.learning_rate * numerical_derivative(f, self.b3)\n",
    "\n",
    "    # query, 즉 미래 값 예측 함수\n",
    "    def predict(self, input_data):    \n",
    "        \n",
    "        z2 = np.dot(input_data, self.W2) + self.b2\n",
    "        a2 = sigmoid(z2)\n",
    "        \n",
    "        z3 = np.dot(a2, self.W3) + self.b3\n",
    "        y = a3 = sigmoid(z3)\n",
    "    \n",
    "        # MNIST 경우는 one-hot encoding 을 적용하기 때문에\n",
    "        # 0 또는 1 이 아닌 argmax() 를 통해 최대 인덱스를 넘겨주어야 함\n",
    "        predicted_num = np.argmax(y)\n",
    "    \n",
    "        return predicted_num\n",
    "        \n",
    "    # obtain W and b\n",
    "    def get_W_b(self):\n",
    "        \n",
    "        return self.W2,  self.b2, self.W3, self.b3\n",
    "    \n",
    "    # 손실 값 계산\n",
    "    def loss_val(self):\n",
    "        \n",
    "        delta = 1e-7    # log 무한대 발산 방지\n",
    "    \n",
    "        z1 = np.dot(self.input_data, self.W2) + self.b2\n",
    "        y1 = sigmoid(z1)\n",
    "        \n",
    "        z2 = np.dot(y1, self.W3) + self.b3\n",
    "        y = sigmoid(z2)\n",
    "    \n",
    "        # cross-entropy \n",
    "        return  -np.sum( self.target_data*np.log(y + delta) + (1-self.target_data)*np.log((1 - y)+delta ) )\n",
    "\n",
    "    # 정확도 측정함수\n",
    "    def accuracy(self, input_data, target_data):\n",
    "        \n",
    "        matched_list = []\n",
    "        not_matched_list = []\n",
    "        \n",
    "        # list which contains (index, label, prediction) value\n",
    "        index_label_prediction_list = []\n",
    "        \n",
    "        # temp list which contains label and prediction in sequence\n",
    "        temp_list = []\n",
    "        \n",
    "        for index in range(len(input_data)):\n",
    "                        \n",
    "            label = int(target_data[index])\n",
    "                        \n",
    "            # normalize\n",
    "            data = (input_data[index, :] / 255.0 * 0.99) + 0.01\n",
    "      \n",
    "            predicted_num = self.predict(data)\n",
    "        \n",
    "            if label == predicted_num:\n",
    "                matched_list.append(index)\n",
    "                \n",
    "            else:\n",
    "                not_matched_list.append(index)\n",
    "                \n",
    "                temp_list.append(index)\n",
    "                temp_list.append(label)\n",
    "                temp_list.append(predicted_num)\n",
    "                \n",
    "                index_label_prediction_list.append(temp_list)\n",
    "                \n",
    "                temp_list = []\n",
    "                \n",
    "        print(\"Current Accuracy = \", len(matched_list)/(len(input_data)) )\n",
    "        \n",
    "        return matched_list, not_matched_list, index_label_prediction_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36468451-3848-4f3c-a2cb-26f944b9de1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_data.shape =  (60000, 785)\n"
     ]
    }
   ],
   "source": [
    "# training data \n",
    "training_data = np.loadtxt('./mnist_train.csv', delimiter=',', dtype=np.float32)\n",
    "\n",
    "print(\"training_data.shape = \", training_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e59a2f8d-9d25-478b-8e9f-9b32335e9ce7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST_Test object is created !!!\n",
      "Neural Network Learning using Numerical Derivative...\n",
      "epochs =  0 , index =  2620 , loss value =  37.49062950508015\n",
      "epochs =  200 , index =  1982 , loss value =  3.36400027773886\n",
      "epochs =  400 , index =  23246 , loss value =  3.456463498592576\n",
      "epochs =  600 , index =  42642 , loss value =  3.1190591194535693\n",
      "epochs =  800 , index =  650 , loss value =  3.44070996837403\n",
      "epochs =  1000 , index =  35021 , loss value =  3.4661055302102177\n",
      "epochs =  1200 , index =  4614 , loss value =  3.5111825613313656\n",
      "epochs =  1400 , index =  19556 , loss value =  3.428615523265362\n",
      "epochs =  1600 , index =  47887 , loss value =  3.7000274148834604\n",
      "epochs =  1800 , index =  8506 , loss value =  3.5622205159941336\n",
      "epochs =  2000 , index =  23696 , loss value =  3.5007472147592034\n",
      "epochs =  2200 , index =  15424 , loss value =  3.084926682340964\n",
      "epochs =  2400 , index =  16082 , loss value =  3.3012951611584382\n",
      "epochs =  2600 , index =  20623 , loss value =  3.345019212488213\n",
      "epochs =  2800 , index =  13836 , loss value =  3.095240358793296\n",
      "epochs =  3000 , index =  30832 , loss value =  3.536148971830893\n",
      "epochs =  3200 , index =  8448 , loss value =  3.62813918218347\n",
      "epochs =  3400 , index =  29355 , loss value =  3.110088576208805\n",
      "epochs =  3600 , index =  10283 , loss value =  3.094825768520454\n",
      "epochs =  3800 , index =  26302 , loss value =  3.511293415064747\n",
      "epochs =  4000 , index =  25681 , loss value =  3.455072070576091\n",
      "epochs =  4200 , index =  42358 , loss value =  3.6114704098806727\n",
      "epochs =  4400 , index =  11888 , loss value =  3.4575836695968283\n",
      "epochs =  4600 , index =  3046 , loss value =  3.0768060735454728\n",
      "epochs =  4800 , index =  44214 , loss value =  3.579679782226821\n",
      "epochs =  5000 , index =  21247 , loss value =  3.5253965434798245\n",
      "epochs =  5200 , index =  13208 , loss value =  3.57685925700748\n",
      "epochs =  5400 , index =  22986 , loss value =  3.5036927256118364\n",
      "epochs =  5600 , index =  37496 , loss value =  3.377019396471403\n",
      "epochs =  5800 , index =  6362 , loss value =  3.1980688591737496\n",
      "epochs =  6000 , index =  48662 , loss value =  3.3622308412239823\n",
      "epochs =  6200 , index =  17637 , loss value =  3.165802091731927\n",
      "epochs =  6400 , index =  37549 , loss value =  3.3812742687107535\n",
      "epochs =  6600 , index =  37432 , loss value =  3.2181762978744284\n",
      "epochs =  6800 , index =  43313 , loss value =  3.6194926498626208\n",
      "epochs =  7000 , index =  5566 , loss value =  3.294046030631873\n",
      "epochs =  7200 , index =  43658 , loss value =  3.439953894389305\n",
      "epochs =  7400 , index =  44459 , loss value =  3.2591527400282185\n",
      "epochs =  7600 , index =  21114 , loss value =  3.2997466132892566\n",
      "epochs =  7800 , index =  8361 , loss value =  3.2327370236866355\n",
      "epochs =  8000 , index =  59053 , loss value =  3.240556646617344\n",
      "epochs =  8200 , index =  2897 , loss value =  3.1376368979921456\n",
      "epochs =  8400 , index =  10789 , loss value =  3.0915817765056572\n",
      "epochs =  8600 , index =  28824 , loss value =  3.346310849485547\n",
      "epochs =  8800 , index =  9887 , loss value =  3.6060822297029196\n",
      "epochs =  9000 , index =  38153 , loss value =  3.4193475641043927\n",
      "epochs =  9200 , index =  46654 , loss value =  3.350012264548428\n",
      "epochs =  9400 , index =  5969 , loss value =  3.362809287396147\n",
      "epochs =  9600 , index =  51761 , loss value =  3.3894290410654184\n",
      "epochs =  9800 , index =  58284 , loss value =  3.6598059241384058\n",
      "epochs =  10000 , index =  4115 , loss value =  3.4696886603136847\n",
      "epochs =  10200 , index =  49853 , loss value =  3.6596853936332474\n",
      "epochs =  10400 , index =  33650 , loss value =  3.4009004127497655\n",
      "epochs =  10600 , index =  12343 , loss value =  3.084361378181261\n",
      "epochs =  10800 , index =  15506 , loss value =  3.5819066613154233\n",
      "epochs =  11000 , index =  36338 , loss value =  3.270953434151741\n",
      "epochs =  11200 , index =  29998 , loss value =  3.404595730856828\n",
      "epochs =  11400 , index =  55175 , loss value =  3.4184548506895727\n",
      "epochs =  11600 , index =  36876 , loss value =  3.555997015370847\n",
      "epochs =  11800 , index =  20847 , loss value =  3.0705977539748\n",
      "epochs =  12000 , index =  45833 , loss value =  3.3339383307132286\n",
      "epochs =  12200 , index =  53527 , loss value =  3.4621576147739805\n",
      "epochs =  12400 , index =  43324 , loss value =  3.499511126686161\n",
      "epochs =  12600 , index =  5549 , loss value =  3.094013045297306\n",
      "epochs =  12800 , index =  36898 , loss value =  3.4749140513714725\n",
      "epochs =  13000 , index =  16729 , loss value =  3.54022139755766\n",
      "epochs =  13200 , index =  26528 , loss value =  3.441696858936974\n",
      "epochs =  13400 , index =  46348 , loss value =  3.280289863415333\n",
      "epochs =  13600 , index =  58121 , loss value =  3.542625661459198\n",
      "epochs =  13800 , index =  22663 , loss value =  3.3766835124681633\n",
      "epochs =  14000 , index =  52486 , loss value =  3.631842989436303\n",
      "epochs =  14200 , index =  27587 , loss value =  3.6480248841634846\n",
      "epochs =  14400 , index =  10489 , loss value =  3.553047995212588\n",
      "epochs =  14600 , index =  26540 , loss value =  3.3128118906819566\n",
      "epochs =  14800 , index =  17988 , loss value =  3.2582957607497476\n",
      "epochs =  15000 , index =  45311 , loss value =  3.555532541419459\n",
      "epochs =  15200 , index =  29893 , loss value =  3.640971194562607\n",
      "epochs =  15400 , index =  54984 , loss value =  3.1185828581931214\n",
      "epochs =  15600 , index =  16508 , loss value =  3.0157497715497947\n",
      "epochs =  15800 , index =  14145 , loss value =  3.2701672048808073\n",
      "epochs =  16000 , index =  5287 , loss value =  3.8331431198012953\n",
      "epochs =  16200 , index =  44996 , loss value =  3.2948826253190147\n",
      "epochs =  16400 , index =  52942 , loss value =  3.52780805075104\n",
      "epochs =  16600 , index =  37706 , loss value =  3.3858705028677534\n",
      "epochs =  16800 , index =  25455 , loss value =  3.1130313576711757\n",
      "epochs =  17000 , index =  7457 , loss value =  3.252845325968293\n",
      "epochs =  17200 , index =  4756 , loss value =  3.432199392814058\n",
      "epochs =  17400 , index =  38260 , loss value =  3.334409018586534\n",
      "epochs =  17600 , index =  13115 , loss value =  3.6167497563532947\n",
      "epochs =  17800 , index =  55590 , loss value =  3.4193391445223993\n",
      "epochs =  18000 , index =  23072 , loss value =  3.3523671727138495\n",
      "epochs =  18200 , index =  1326 , loss value =  2.980047338100834\n",
      "epochs =  18400 , index =  18153 , loss value =  3.4022203965630524\n",
      "epochs =  18600 , index =  54309 , loss value =  3.066520556500381\n",
      "epochs =  18800 , index =  15236 , loss value =  3.354135607119084\n",
      "epochs =  19000 , index =  20040 , loss value =  3.3892630603108502\n",
      "epochs =  19200 , index =  45698 , loss value =  3.0980669163564083\n",
      "epochs =  19400 , index =  2124 , loss value =  3.4487601532383754\n",
      "epochs =  19600 , index =  18261 , loss value =  2.9426043911079973\n",
      "epochs =  19800 , index =  39089 , loss value =  3.2460864210730835\n",
      "epochs =  20000 , index =  54251 , loss value =  3.3405193722384787\n",
      "epochs =  20200 , index =  31241 , loss value =  3.0962988848874633\n",
      "epochs =  20400 , index =  49974 , loss value =  3.4859975020075966\n",
      "epochs =  20600 , index =  9010 , loss value =  3.328359998575554\n",
      "epochs =  20800 , index =  3416 , loss value =  3.2999067494559435\n",
      "epochs =  21000 , index =  16311 , loss value =  3.4066245962838533\n",
      "epochs =  21200 , index =  51073 , loss value =  3.308212052086898\n",
      "epochs =  21400 , index =  45226 , loss value =  3.7156659456993766\n",
      "epochs =  21600 , index =  57290 , loss value =  3.245247267549386\n",
      "epochs =  21800 , index =  33880 , loss value =  3.305388127717489\n",
      "epochs =  22000 , index =  35020 , loss value =  3.3622623602822412\n",
      "epochs =  22200 , index =  18801 , loss value =  3.011997231589634\n",
      "epochs =  22400 , index =  51862 , loss value =  3.1704798289000773\n",
      "epochs =  22600 , index =  37595 , loss value =  3.603471831868949\n",
      "epochs =  22800 , index =  28178 , loss value =  3.317383031870086\n",
      "epochs =  23000 , index =  10180 , loss value =  3.0845303153044563\n",
      "epochs =  23200 , index =  5399 , loss value =  3.5015428753430187\n",
      "epochs =  23400 , index =  44757 , loss value =  3.460745354654154\n",
      "epochs =  23600 , index =  4684 , loss value =  3.5645661876859234\n",
      "epochs =  23800 , index =  53640 , loss value =  3.1318921512196365\n",
      "epochs =  24000 , index =  46841 , loss value =  3.121612167634917\n",
      "epochs =  24200 , index =  41052 , loss value =  3.177603046162461\n",
      "epochs =  24400 , index =  37431 , loss value =  3.3150666762800034\n",
      "epochs =  24600 , index =  21080 , loss value =  3.258199382986905\n",
      "epochs =  24800 , index =  39474 , loss value =  3.337124601166321\n",
      "epochs =  25000 , index =  42458 , loss value =  3.461206416554878\n",
      "epochs =  25200 , index =  4705 , loss value =  3.4307237946669926\n",
      "epochs =  25400 , index =  29508 , loss value =  3.514070265677254\n",
      "epochs =  25600 , index =  27862 , loss value =  3.412778219149885\n",
      "epochs =  25800 , index =  51811 , loss value =  3.200649153979091\n",
      "epochs =  26000 , index =  29906 , loss value =  3.101941684208855\n",
      "epochs =  26200 , index =  656 , loss value =  3.3680979645923537\n",
      "epochs =  26400 , index =  37692 , loss value =  3.367666196537984\n",
      "epochs =  26600 , index =  34003 , loss value =  3.2939812505945136\n",
      "epochs =  26800 , index =  3036 , loss value =  3.4804965097878413\n",
      "epochs =  27000 , index =  34009 , loss value =  3.5757526872332464\n",
      "epochs =  27200 , index =  57162 , loss value =  3.246237021364406\n",
      "epochs =  27400 , index =  7726 , loss value =  3.3358095881595666\n",
      "epochs =  27600 , index =  902 , loss value =  3.6719101012756066\n",
      "epochs =  27800 , index =  59340 , loss value =  3.3028735169659362\n",
      "epochs =  28000 , index =  9865 , loss value =  3.8803177508873503\n",
      "epochs =  28200 , index =  48897 , loss value =  3.452800066192809\n",
      "epochs =  28400 , index =  2794 , loss value =  3.49757849343712\n",
      "epochs =  28600 , index =  14903 , loss value =  3.1514046665814437\n",
      "epochs =  28800 , index =  4506 , loss value =  3.1609024180108247\n",
      "epochs =  29000 , index =  10194 , loss value =  3.4536618820712683\n",
      "epochs =  29200 , index =  36994 , loss value =  3.2541793046719616\n",
      "epochs =  29400 , index =  9918 , loss value =  3.271874872335933\n",
      "epochs =  29600 , index =  2616 , loss value =  3.4143032278674665\n",
      "epochs =  29800 , index =  53438 , loss value =  3.423685852036618\n",
      "epochs =  30000 , index =  58198 , loss value =  3.3776940775767046\n",
      "\n",
      "Elapsed Time =>  11:50:31.923925\n"
     ]
    }
   ],
   "source": [
    "#hyper-parameter\n",
    "\n",
    "i_nodes = training_data.shape[1] - 1    # input nodes 개수\n",
    "h1_nodes = 8  # hidden nodes 개수. Test 8->30\n",
    "o_nodes = 10    # output nodes 개수\n",
    "lr = 1e-2      # learning rate\n",
    "epochs = 1   # 반복횟수\n",
    "\n",
    "# 손실함수 값을 저장할 list 생성\n",
    "loss_val_list = []\n",
    "\n",
    "# MNIST_Test 객체 생성\n",
    "obj = MNIST_Test(i_nodes, h1_nodes, o_nodes, lr)\n",
    "\n",
    "print(\"Neural Network Learning using Numerical Derivative...\")\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    for step in range(30001):    \n",
    "                \n",
    "        # input_data, target_data normalize   \n",
    "        index = np.random.randint(0, len(training_data)-1)\n",
    "        input_data = ((training_data[index, 1:] / 255.0) * 0.99) + 0.01\n",
    "        \n",
    "        target_data = np.zeros(o_nodes) + 0.01    \n",
    "        target_data[int(training_data[index, 0])] = 0.99\n",
    "        \n",
    "        obj.train(input_data, target_data)\n",
    "        \n",
    "        if (step % 200 == 0):\n",
    "            print(\"epochs = \", step, \", index = \", index, \", loss value = \", obj.loss_val())\n",
    "            \n",
    "        # 손실함수 값 저장\n",
    "        loss_val_list.append(obj.loss_val())        \n",
    "\n",
    "end_time = datetime.now()\n",
    "        \n",
    "print(\"\")\n",
    "print(\"Elapsed Time => \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd70a635-e1e7-43d4-ac32-f83fa0684725",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data.shape =  (10000, 785)\n",
      "Current Accuracy =  0.0958\n"
     ]
    }
   ],
   "source": [
    "test_data = np.loadtxt('./mnist_test.csv', delimiter=',', dtype=np.float32)\n",
    "print(\"test_data.shape = \", test_data.shape)\n",
    "\n",
    "test_input_data = test_data[ :, 1: ]\n",
    "test_target_data = test_data[ :, 0 ]\n",
    "\n",
    "(true_list_1, false_list_1, index_label_prediction_list) = obj.accuracy(test_input_data, test_target_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69bc9a8-80e4-44d6-8821-cf6e3811da86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실함수 추세 확인\n",
    "x_data_list = [ index for index in range(len(training_data)) ]\n",
    "Y_DATA_LIST = []\n",
    "\n",
    "for index in range(0, len(loss_val_list), 500):\n",
    "    Y_DATA_LIST.append(loss_val_list[index])\n",
    "    \n",
    "plt.title('MNIST Loss Value Trend')\n",
    "plt.xlabel('data index ( X 500)')\n",
    "plt.ylabel('loss value')\n",
    "plt.grid()\n",
    "#plt.ylim(2.1, 7.1)\n",
    "#plt.plot(x_data_list, loss_val_list, color='b')\n",
    "plt.plot(Y_DATA_LIST, color='b')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
